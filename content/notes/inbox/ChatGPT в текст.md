---
title: "ChatGPT в текст"
---

У цій статті ми розглянемо, як за допомогою узагальненого API попередньо навчених трансформаторів v3 (GPT-3) з [OpenAI](https://openai.com/) згенерувати текстовий вміст з рядкового запиту за допомогою коду на Python.

Якщо ви знайомі з ChatGPT, GPT-3 API працює так само, як і цей додаток: ви даєте йому фрагмент тексту, а він повертає вам фрагмент тексту у відповідь. Це тому, що ChatGPT пов'язаний з GPT-3, але представляє свої результати в додатку для чату, а не через прямі виклики API.

Якщо ви коли-небудь думали, що було б круто інтегрувати додатки на основі трансформаторів у ваш власний код, GPT-3 дозволяє вам це зробити за допомогою свого API на Python.

У цій статті ми розглянемо, як працювати з GPT-3 з коду на Python, щоб генерувати контент на основі власних підказок - і скільки це вам коштуватиме.

Примітка: Ця стаття значною мірою натхненна частиною [чудової доповіді Скотта Шоуолтера про створення персонального асистента на CodeMash 2023] (https://www.codemash.org/session-details/?id=380434), і я вдячний йому за те, що він показав мені, наскільки просто викликати OpenAI API з Python_.

Навіщо використовувати GPT-3, якщо доступний ChatGPT?
----------------------------------------

Перш ніж ми заглибимось у цю тему, слід зазначити, що GPT-3 є старішим за ChatGPT і є попередником цієї технології. З огляду на це, виникає природне запитання: "Навіщо мені використовувати старий спосіб роботи?".

Відповідь на нього досить проста: ChatGPT побудований як інтерактивний чат-додаток, який безпосередньо спілкується з користувачем. GPT-3, з іншого боку, є повноцінним API, якому можна давати будь-які підказки, які ви хочете.

Наприклад, якщо вам потрібно швидко _написати_ електронного листа клієнту для перегляду і доопрацювання, ви можете дати GPT-3 підказку "Згенерувати ввічливу відповідь на це запитання клієнта (тут запитання клієнта), яка дасть йому огляд теми на високому рівні".

Після цього GPT-3 поверне вам згенерований ним текст, і ваша команда підтримки зможе внести зміни в цей текст, а потім надіслати його далі.

Таким чином, GPT-3 дозволяє заощадити час на написанні відповідей, але при цьому дає вам редакторський контроль для перевірки фактів і уникнення плутанини, яка може виникнути, наприклад, при взаємодії з ChatGPT.

GPT-3 корисний за будь-яких обставин, коли вам потрібно згенерувати текст за певним запитом, а потім переглянути його для подальшого використання.

Отримання ключа API GPT-3
-----------------------
Перш ніж ви зможете використовувати GPT-3, вам потрібно створити обліковий запис і отримати ключ API від OpenAI.

Створити обліковий запис досить просто, і, можливо, ви вже робили це, якщо працювали з ChatGPT.

Спочатку перейдіть на сторінку [Log in page] (https://openai.com/api/login/) і увійдіть, використовуючи ваш існуючий обліковий запис або облікові записи Google чи Microsoft.

Якщо у вас ще немає облікового запису, ви можете натиснути на посилання Зареєструватися, щоб зареєструватися.

Після входу ви побачите екран, подібний до наведеного нижче:

![OpenAI Dashboard](https://accessibleai.dev/img/OpenAI/OpenAIAfterLogin.png)

Хоча тут є багато цікавих посилань на документацію та приклади, нас цікавить отримання ключа API, який ми можемо використовувати в Python-коді.

Щоб отримати цей ключ API, натисніть на свою фотографію та назву організації у верхньому правому куті, а потім виберіть _Переглянути ключі API_.

![Переглянути ключі API](https://accessibleai.dev/img/OpenAI/DashboardContextMenu.png)

Звідси натисніть _\+ Створити новий секретний ключ_, щоб згенерувати новий секретний ключ. **Цей ключ буде видимим лише один раз і ви не зможете його відновити, тому скопіюйте його в безпечне місце**.

Після того, як у вас є ключ API, настав час перейти до коду на Python.

Імпорт OpenAI та вказівка ключа API
--------------------------------------------
До кінця цієї статті я покажу вам фрагменти коду, які можуть потрапити до `.py`-файлу.

Якщо ви виконуєте ці кроки, ви можете назвати цей файл `gpt3.py` і використати якусь версію [PyCharm] (https://www.jetbrains.com/pycharm/).

Перше, що нам потрібно зробити, це встановити залежність OpenAI. Для цього ви можете скористатися панеллю менеджера пакунків PyCharm, але більш універсальним способом буде використання pip або подібних програм для встановлення залежності openai наступним чином:

    pip install openai
    

Після цього додайте пару рядків для імпорту OpenAI і встановіть ключ API, який ви отримали раніше:

    import openai as ai
    
    ai.api_key = 'sk-somekeygoeshere' # замініть на ваш ключ, отриманий раніше
    

Цей код має працювати, однак, з різних причин, вбудовувати ключ безпосередньо у файл - дуже погана практика:

Прив'язка файлу до певного ключа зменшує гнучкість використання того самого коду в різних контекстах пізніше.

Розміщення маркерів доступу в коді є дуже поганим кроком, якщо ваш код коли-небудь покине вашу організацію або навіть якщо він потрапить до команди чи особи, яка не повинна мати доступу до цього ресурсу.

Особливо поганою ідеєю є розміщення коду на GitHub або інших публічних сховищах коду, де його можуть помітити інші, в тому числі автоматизовані боти, які шукають ключі в публічному коді.

Натомість краще оголосити ключ API як змінну оточення, а потім використовувати os для отримання цього ключа за його ім'ям:

    import os
    import openai as ai
    
    # Отримання ключа зі змінної оточення на машині, на якій запущено програму
    ai.api_key = os.environ.get("OPENAI_API_KEY")
    

Після того, як ви встановили ключ в OpenAI, ви можете починати генерувати прогнози.

Створення функції для генерації прогнозу
--------------------------------------------

Нижче наведено коротку функцію, яка звертається до [API завершення] OpenAI (https://beta.openai.com/docs/api-reference/completions/create), щоб згенерувати серію текстових "токенів" із заданої підказки:

    def generate_gpt3_response(user_text, print_output=False):
        """
        Запитайте OpenAI GPT-3 за певним ключем і отримайте відповідь
        :type user_text: str текст користувача для запиту
        тип print_output: boolean - друкувати чи ні вихідний JSON
        """
        completions = ai.Completion.create(
            engine='text-davinci-003', # Визначає якість, швидкість та вартість.
            temperature=0.5, # Рівень креативності у відповіді
            prompt=user_text, # Те, що ввів користувач
            max_tokens=100, # Максимальна кількість токенів у запиті та відповіді
            n=1, # Кількість завершень для генерації
            stop=None, # Необов'язковий параметр для контролю генерації відповідей
        )
  
 # Відображення виводу може бути корисним, якщо щось піде не так
        if print_output:
            print(completions)
    
        # Повернути текст першого варіанту відповіді
        return completions.choices[0].text
    

Я намагався зробити наведений вище код досить добре задокументованим, але давайте підсумуємо його коротко:

Код отримує деякий `user_text` і передає його об'єкту openai разом з низкою параметрів (про які ми скоро поговоримо).

Потім цей код звертається до API завершень OpenAI і отримує відповідь, яка містить масив згенерованих завершень у вигляді `completions.choices`. У нашому випадку цей масив завжди буде містити 1 завершення, тому що `n` встановлено в 1.

`temperature` може здатися незвичним, але воно відноситься до [імітованого відпалу](https://en.wikipedia.org/wiki/Simulated_annealing), що є металургійною концепцією, яка застосовується в машинному навчанні для впливу на швидкість навчання алгоритму. Низька температура (близько 0) буде давати дуже чітко визначені відповіді, в той час як більш високе число (близько 1) буде більш творчим у своїх відповідях.

Я хочу виділити параметр `max_tokens`. Тут токен - це слово або знак пунктуації, з яких складається або підказка для введення (`user_text`), або вихідні дані.

Це означає, що якщо ви задасте GPT-3 `max_tokens` 10 і `prompt` "How are you?", ви вже використали 4 максимальних токени, і відповідь, яку ви отримаєте, буде довжиною до 6 токенів максимум.

### Ціноутворення та GPT-3

Далі, давайте зупинимося на ціновому аспекті. З GPT-3 ви платите на основі кількості токенів, які ви відправляєте і отримуєте від API, і в залежності від того, який _рушій_ ви вирішили використовувати.

![OpenAI Pricing Data](https://accessibleai.dev/img/OpenAI/Pricing.png)

На момент написання цієї статті ціна коливається від 4 сотих відсотка до 2 центів за тисячу токенів, які проходять через GPT-3. Однак, ви завжди повинні перевіряти [останню інформацію про ціни] (https://openai.com/api/pricing/) перед тим, як приймати рішення.

Ви можете зробити кілька речей, щоб контролювати витрати за допомогою GPT-3:

По-перше, ви можете обмежити `max_tokens` в запиті до API, як ми зробили вище.

По-друге, ви можете обмежити `n` до 1, щоб згенерувати лише одну чернетку відповіді, а не декілька окремих чернеток.

По-третє, ви можете використовувати менш продуктивну / точну мовну модель за нижчою ціною. У наведеному вище коді використовувалася модель DaVinci, але Кюрі, Беббідж і Ада працюють швидше і дешевше, ніж DaVinci.

Однак, якщо якість вашого результату має першорядне значення, використання найпотужнішої мовної моделі може бути для вас найважливішим фактором.

Ви можете отримати більше інформації про доступні моделі за допомогою [models API](https://beta.openai.com/docs/api-reference/models/list).

Ви також можете перерахувати ідентифікатори всіх доступних моделей за допомогою наступного коду на Python:

    models = ai.Model.list()
    
    for model in models.data:
        print(model.id)
    

Звичайно, вам потрібно буде шукати більше інформації про кожну модель, яка вас цікавить, оскільки цей список з часом буде розширюватися.

Створення тексту з підказки
-----------------------------

Нарешті, давайте об'єднаємо всі частини в головний метод, викликавши нашу функцію:

    if __name__ == '__main__':
        prompt = 'Розкажіть мені, що таке модель GPT-3 у дружній манері'
        response = generate_gpt3_response(prompt)
        
        print(response)
    

Це надасть певну підказку нашій функції, а потім відобразить відповідь у консолі.

Для мене це згенерувало наступну цитату:

> GPT-3 - це тип моделі штучного інтелекту, який використовує обробку природної мови для створення тексту. Вона навчається на величезному наборі текстових даних і може використовуватися для генерування природних відповідей на запитання або підказки. Його можна використовувати для створення історій, резюме і навіть для написання коду.

Якщо у вас виникли проблеми, я рекомендую викликати `generate_gpt3_response` із параметром `print_output`, встановленим у значення `True`. Це виведе JSON, отриманий від OpenAI, безпосередньо на консоль, що може призвести до виникнення потенційних проблем.

Нарешті, через високий трафік в ChatGPT на даний момент ви можете іноді отримувати перевантажені коди відповідей на помилки від сервера. Якщо це сталося, спробуйте ще раз через деякий час.

Заключні думки
----------------

Я вважаю, що код для роботи з трансформаторними моделями OpenAI дуже простий і зрозумілий.

На момент написання цієї статті я вивчаю трансформатори вже близько півроку, і я думаю, що у всіх нас був колективний момент "Ого, як ми можемо застосувати це в наших додатках?", коли був представлений ChatGPT.

OpenAI API дозволяє працювати з трансформаторними моделями, такими як GPT-3 та іншими, використовуючи дуже невелику кількість коду на Python за досить доступною ціною.

Наразі ChatGPT домінує для безпосередньої взаємодії з користувачем, але GPT-3 дозволяє нам використовувати подібний рівень потужності в наших додатках для підготовки відповідей, створення контенту для ігор та історій, а також для інших творчих проектів.

Я з нетерпінням чекаю, куди нас приведуть трансформатори в майбутньому. Якщо ви створили щось цікаве за допомогою цих API, я буду радий почути про це.

* * *

Якщо ви знайшли цей контент корисним, [дайте мені знати] (https://twitter.com/integerman)!

Цей контент також доступний на інших платформах:

*   [LinkedIn Newsletter](https://www.linkedin.com/newsletters/accessible-ai-6973483714404118528/ "LinkedIn Newsletter")
*   [Medium Publication](https://medium.com/accessibleai "Medium Publication")
*   [YouTube Channel](https://www.youtube.com/channel/UCtzmz6BfJqDx-8IHkh6ovwA "YouTube Channel")

*   [Transformers](https://accessibleai.dev/tags/transformers/)
*   [Python](https://accessibleai.dev/tags/python/)
*   [GPT-3](https://accessibleai.dev/tags/gpt-3/)

![Matt Eland avatar](https://accessibleai.dev/img/Profile.png) [![Microsoft MVP Logo](https://accessibleai.dev/img/MVPVertical.png)](https://mvp.microsoft.com/en-us/PublicProfile/5005207?fullName=Matt%20Eland "View Microsoft MVP Profile")

Matt Eland

[Microsoft MVP in AI](https://mvp.microsoft.com/en-us/PublicProfile/5005207?fullName=Matt%20Eland), Professional Programming Instructor

*   [](https://twitter.com/IntegerMan "Twitter Profile")
*   [](https://linkedin.com/in/matteland "LinkedIn Profile")
*   [](https://github.com/integerman "GitHub Profile")
*   [](https://www.youtube.com/c/MattEland "YouTube Channel")

Метт - викладач програмної інженерії, який виховує майбутніх розробників і відкриває їм світ, щоб вони робили дивовижні речі. До викладацької діяльності Метт працював у сфері стартапів та програмного забезпечення як послуги, використовуючи .NET та JavaScript.

Метт - сертифікований Microsoft [Azure Data Scientist] (https://www.credly.com/badges/53ace869-2160-4fcd-be00-271bc5ada4aa/public_url) та [AI Engineer] (https://www.credly.com/badges/ff77beed-645f-4d8f-9834-c8177915cbc8/public_url) і здобуває ступінь магістра з аналітики даних, зосереджуючись на машинному навчанні та штучному інтелекті, оскільки він продовжує створювати, вивчати нові речі та шукати способи поділитися ними зі спільнотою.

[" Попередня

Хочете створити чат-бота? 🎵

(https://accessibleai.dev/post/do_you_want_to_build_a_chatbot/)

[Далі "

Розуміння навчання з підкріпленням

](https://accessibleai.dev/post/reinforcement_learning/)

Copyright © 2023 [Метт Еланд] (https://matteland.dev/). Всі права захищені.

Copyright © 2023 [Matt Eland](https://matteland.dev/). All Rights Reserved.

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/border_3.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/border_3.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/border_3.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/border_3.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/border_3.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/border_3.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)

![](https://ssl.gstatic.com/s2/oz/images/stars/po/bubblev1/spacer.gif)